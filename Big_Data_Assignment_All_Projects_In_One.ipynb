{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBA Module 4 Project 1,2 and 3 has been combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Spark Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the packages and setting up environment\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "spark_path = 'D:\\\\spark-2.4.3-bin-hadoop2.7'\n",
    "os.environ['SPARK_HOME']= spark_path\n",
    "os.environ['HADOOP_HOME']=spark_path\n",
    "sys.path.append(spark_path+'/bin')\n",
    "sys.path.append(spark_path+'/python')\n",
    "sys.path.append(spark_path+'/python/pyspark')\n",
    "sys.path.append(spark_path+'/python/lib')\n",
    "sys.path.append(spark_path+'/python/lib/pyspark.zip')\n",
    "sys.path.append(spark_path+'/python/lib/py4j-0.10.4-src.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Dur: double (nullable = true)\n",
      " |-- Proto: string (nullable = true)\n",
      " |-- SrcAddr: string (nullable = true)\n",
      " |-- Sport: string (nullable = true)\n",
      " |-- Dir: string (nullable = true)\n",
      " |-- DstAddr: string (nullable = true)\n",
      " |-- Dport: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- sTos: double (nullable = true)\n",
      " |-- TotPkts: integer (nullable = true)\n",
      " |-- TotBytes: integer (nullable = true)\n",
      " |-- SrcBytes: integer (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      " |-- Attacked: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('tree').getOrCreate()\n",
    "# Reading the data\n",
    "df = spark.read.csv('D:\\\\ashu\\\\REVA\\\\MBA\\\\Mod4\\\\preprocessed_13.csv', inferSchema=True, header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, _c0: string, StartTime: string, Dur: string, Proto: string, SrcAddr: string, Sport: string, Dir: string, DstAddr: string, Dport: string, State: string, sTos: string, TotPkts: string, TotBytes: string, SrcBytes: string, Label: string, Attacked: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1889141"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('StartTime', 'string'),\n",
       " ('Dur', 'double'),\n",
       " ('Proto', 'string'),\n",
       " ('SrcAddr', 'string'),\n",
       " ('Sport', 'string'),\n",
       " ('Dir', 'string'),\n",
       " ('DstAddr', 'string'),\n",
       " ('Dport', 'string'),\n",
       " ('State', 'string'),\n",
       " ('sTos', 'double'),\n",
       " ('TotPkts', 'int'),\n",
       " ('TotBytes', 'int'),\n",
       " ('SrcBytes', 'int'),\n",
       " ('Label', 'string'),\n",
       " ('Attacked', 'int')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------------------+-----+--------------+-----+-----+-------------+-----+-----+----+-------+--------+--------+--------------------+--------+\n",
      "|_c0|           StartTime|               Dur|Proto|       SrcAddr|Sport|  Dir|      DstAddr|Dport|State|sTos|TotPkts|TotBytes|SrcBytes|               Label|Attacked|\n",
      "+---+--------------------+------------------+-----+--------------+-----+-----+-------------+-----+-----+----+-------+--------+--------+--------------------+--------+\n",
      "|  0|2011/08/15 17:13:...|          5.170088|  tcp|  2.157.248.25| 3146|   ->|147.32.84.118| 6881| S_RA| 0.0|      4|     252|     132|flow=Background-T...|       0|\n",
      "|  1|2011/08/15 17:15:...| 6.609413000000001|  tcp|148.100.181.73|51668|   ->|147.32.84.118| 6881| S_RA| 0.0|      4|     252|     132|flow=Background-T...|       0|\n",
      "|  2|2011/08/15 17:20:...|1.7971849999999998|  tcp|61.177.250.153| 7212|   ->| 147.32.84.40| 4899| S_RA| 0.0|      4|     244|     124|flow=Background-T...|       0|\n",
      "|  3|2011/08/15 17:20:...|1.9599349999999998|  tcp|92.241.212.170|49530|   ->|147.32.84.229|13363|SR_SA| 0.0|      5|     360|     216|flow=Background-T...|       0|\n",
      "|  4|2011/08/15 17:20:...|          1.016078|  tcp|92.241.212.170|49530|   ->|147.32.84.229|13363|SR_SA| 0.0|      3|     216|     138|flow=Background-T...|       0|\n",
      "|  5|2011/08/15 17:20:...|          1.928074|  tcp|92.241.212.170|49537|   ->|147.32.84.229|  443|SR_SA| 0.0|      5|     360|     216|flow=Background-T...|       0|\n",
      "|  6|2011/08/15 17:20:...|0.9799329999999999|  tcp|92.241.212.170|49530|   ->|147.32.84.229|13363|SR_SA| 0.0|      3|     184|     122|flow=Background-T...|       0|\n",
      "|  7|2011/08/15 17:20:...|          1.000168|  tcp|92.241.212.170|49537|   ->|147.32.84.229|  443|SR_SA| 0.0|      3|     216|     138|flow=Background-T...|       0|\n",
      "|  8|2011/08/15 17:20:...|          1.059955|  tcp|92.241.212.170|49530|   ->|147.32.84.229|13363|SR_SA| 0.0|      3|     184|     122|flow=Background-T...|       0|\n",
      "|  9|2011/08/15 17:20:...|         10.911062|  tcp| 64.32.110.145|56141|   ->|147.32.84.229|  443|SR_SA| 0.0|     17|    1236|     606|flow=Background-T...|       0|\n",
      "+---+--------------------+------------------+-----+--------------+-----+-----+-------------+-----+-----+----+-------+--------+--------+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display top 10 records\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target into numerical categories, not required in this case, as it is already numeric\n",
    "# labelIndexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, DateType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, StartTime='2011/08/15 17:13:51.499832', Dur=5.170088, Proto='tcp', SrcAddr='2.157.248.25', Sport='3146', Dir='   ->', DstAddr='147.32.84.118', Dport='6881', State='S_RA', sTos=0.0, TotPkts=4, TotBytes=252, SrcBytes=132, Label='flow=Background-TCP-Attempt', Attacked=0),\n",
       " Row(_c0=1, StartTime='2011/08/15 17:15:33.511251', Dur=6.609413000000001, Proto='tcp', SrcAddr='148.100.181.73', Sport='51668', Dir='   ->', DstAddr='147.32.84.118', Dport='6881', State='S_RA', sTos=0.0, TotPkts=4, TotBytes=252, SrcBytes=132, Label='flow=Background-TCP-Attempt', Attacked=0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider only hour\n",
    "df1 = df.withColumn(\"StartTime\", df[\"StartTime\"].substr(12,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, StartTime='17', Dur=5.170088, Proto='tcp', SrcAddr='2.157.248.25', Sport='3146', Dir='   ->', DstAddr='147.32.84.118', Dport='6881', State='S_RA', sTos=0.0, TotPkts=4, TotBytes=252, SrcBytes=132, Label='flow=Background-TCP-Attempt', Attacked=0),\n",
       " Row(_c0=1, StartTime='17', Dur=6.609413000000001, Proto='tcp', SrcAddr='148.100.181.73', Sport='51668', Dir='   ->', DstAddr='147.32.84.118', Dport='6881', State='S_RA', sTos=0.0, TotPkts=4, TotBytes=252, SrcBytes=132, Label='flow=Background-TCP-Attempt', Attacked=0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Proto='udt', count=7),\n",
       " Row(Proto='rtcp', count=1334),\n",
       " Row(Proto='rtp', count=1757),\n",
       " Row(Proto='icmp', count=14123),\n",
       " Row(Proto='tcp', count=359837),\n",
       " Row(Proto='udp', count=1512083)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for each protocol type, what was the count\n",
    "df1.groupBy('Proto').count().orderBy('count').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Proto='others', count=3098),\n",
       " Row(Proto='icmp', count=14123),\n",
       " Row(Proto='tcp', count=359837),\n",
       " Row(Proto='udp', count=1512083)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert udt, rtcp and rtp into others\n",
    "df2 = df1.withColumn(\"Proto\", when(df[\"Proto\"] == 'udt', 'others').otherwise(df1[\"Proto\"]))\n",
    "df3 = df2.withColumn(\"Proto\", when(df2[\"Proto\"] == 'rtcp', 'others').otherwise(df2[\"Proto\"]))\n",
    "df4 = df3.withColumn(\"Proto\", when(df3[\"Proto\"] == 'rtp', 'others').otherwise(df3[\"Proto\"]))\n",
    "df4.groupBy('Proto').count().orderBy('count').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(State='FRPA_R', count=1),\n",
       " Row(State='FSPAC_SRPA', count=1),\n",
       " Row(State='SRA_FSRA', count=1),\n",
       " Row(State='SPAC_FSRPA', count=1),\n",
       " Row(State='FSPA_FRA', count=1),\n",
       " Row(State='FPA_FPAC', count=1),\n",
       " Row(State='SRPAC_SRPA', count=1),\n",
       " Row(State='FSAEC_FSPAE', count=1),\n",
       " Row(State='FSPA_FSPAC', count=1),\n",
       " Row(State='FSRPAC_FSRPA', count=1),\n",
       " Row(State='SPA_', count=1),\n",
       " Row(State='SR_SRA', count=1),\n",
       " Row(State='SPA_RA', count=1),\n",
       " Row(State='PA_FRA', count=1),\n",
       " Row(State='SPAEC_SPA', count=1),\n",
       " Row(State='SRPAC_FSPA', count=1),\n",
       " Row(State='SA_SPA', count=1),\n",
       " Row(State='FSPA_', count=1),\n",
       " Row(State='FRA_PA', count=1),\n",
       " Row(State='FSRPA_FPA', count=1),\n",
       " Row(State='FSRAEC_FSPA', count=1),\n",
       " Row(State='RPAC_PA', count=1),\n",
       " Row(State='_FA', count=1),\n",
       " Row(State='FPAC_FPA', count=1),\n",
       " Row(State='FSRPAC_FSA', count=1),\n",
       " Row(State='FRPAC_FPA', count=1),\n",
       " Row(State='FS_RA', count=1),\n",
       " Row(State='FSA_', count=1),\n",
       " Row(State='SR_RPA', count=1),\n",
       " Row(State='SRPA_FRPA', count=1),\n",
       " Row(State='FPA_FSPA', count=1),\n",
       " Row(State='_RPA', count=1),\n",
       " Row(State='FSPA_R', count=1),\n",
       " Row(State='S_A', count=1),\n",
       " Row(State='SA_FSRPA', count=1),\n",
       " Row(State='SRC', count=1),\n",
       " Row(State='SRA_FPA', count=1),\n",
       " Row(State='FPA_PAC', count=1),\n",
       " Row(State='FSAU_SRA', count=1),\n",
       " Row(State='RPA_RA', count=1),\n",
       " Row(State='S_R', count=1),\n",
       " Row(State='FSRPAC_SRPA', count=1),\n",
       " Row(State='SRA_R', count=1),\n",
       " Row(State='FSRPA_FSPAC', count=1),\n",
       " Row(State='RA_FRA', count=1),\n",
       " Row(State='FPA_FRPAC', count=1),\n",
       " Row(State='RPA_RPA', count=1),\n",
       " Row(State='FSPA_FPA', count=2),\n",
       " Row(State='FSRPA_FSRA', count=2),\n",
       " Row(State='SRC_', count=2),\n",
       " Row(State='FRA_RPA', count=2),\n",
       " Row(State='UNK', count=2),\n",
       " Row(State='SRA_FSRPA', count=2),\n",
       " Row(State='FSRPAC_SPA', count=2),\n",
       " Row(State='SA_FSPA', count=2),\n",
       " Row(State='FRPA_RPA', count=2),\n",
       " Row(State='FSRAEC_FSA', count=2),\n",
       " Row(State='R_PA', count=2),\n",
       " Row(State='RPA_', count=2),\n",
       " Row(State='FRA_FRPA', count=2),\n",
       " Row(State='F_', count=3),\n",
       " Row(State='SPA_FSA', count=3),\n",
       " Row(State='RA_A', count=3),\n",
       " Row(State='FSRAE_FSA', count=3),\n",
       " Row(State='SRPA_SPAC', count=3),\n",
       " Row(State='SRPA_FSPAC', count=3),\n",
       " Row(State='FSRA_SRA', count=3),\n",
       " Row(State='FSRPAEC_FSPA', count=3),\n",
       " Row(State='FPA_FRA', count=3),\n",
       " Row(State='SR_RA', count=3),\n",
       " Row(State='SPAC_FSPA', count=4),\n",
       " Row(State='SR_FSA', count=4),\n",
       " Row(State='_FPA', count=4),\n",
       " Row(State='SRPAEC_SPA', count=4),\n",
       " Row(State='FSPAEC_FSRA', count=4),\n",
       " Row(State='FPA_RA', count=4),\n",
       " Row(State='RA_PA', count=4),\n",
       " Row(State='FSAU_FSRA', count=4),\n",
       " Row(State='FRA_FPA', count=5),\n",
       " Row(State='FRPA_', count=5),\n",
       " Row(State='RPA_A', count=5),\n",
       " Row(State='A_RPA', count=5),\n",
       " Row(State='SRPA_FSRA', count=6),\n",
       " Row(State='DCE', count=6),\n",
       " Row(State='SRPAC_SPA', count=6),\n",
       " Row(State='_PA', count=7),\n",
       " Row(State='FSA_SA', count=7),\n",
       " Row(State='SA_FR', count=7),\n",
       " Row(State='URO', count=8),\n",
       " Row(State='FSPAC_FSA', count=8),\n",
       " Row(State='RA_FPA', count=8),\n",
       " Row(State='PA_RA', count=8),\n",
       " Row(State='SPAC_SRPA', count=9),\n",
       " Row(State='SR_A', count=9),\n",
       " Row(State='RPA_FRPA', count=9),\n",
       " Row(State='FA_RA', count=9),\n",
       " Row(State='SEC_', count=9),\n",
       " Row(State='FA_FPA', count=10),\n",
       " Row(State='SA_FSRA', count=10),\n",
       " Row(State='PA_PAC', count=10),\n",
       " Row(State='PAC_PA', count=10),\n",
       " Row(State='FSPAEC_FSA', count=10),\n",
       " Row(State='FSRPA_SRA', count=11),\n",
       " Row(State='FSPAEC_FSPA', count=13),\n",
       " Row(State='FRPA_FRPA', count=14),\n",
       " Row(State='SRPA_SRA', count=14),\n",
       " Row(State='FRA_R', count=16),\n",
       " Row(State='FA_A', count=17),\n",
       " Row(State='FA_FRA', count=17),\n",
       " Row(State='PA_FRPA', count=18),\n",
       " Row(State='FSPAC_FSRA', count=18),\n",
       " Row(State='FRA_FA', count=19),\n",
       " Row(State='A_RA', count=20),\n",
       " Row(State='SRA_SRA', count=24),\n",
       " Row(State='RC_', count=24),\n",
       " Row(State='FRPA_PA', count=26),\n",
       " Row(State='SRA_RA', count=26),\n",
       " Row(State='FSPAC_FSRPA', count=27),\n",
       " Row(State='FSAU_FSA', count=27),\n",
       " Row(State='RPA_FPA', count=28),\n",
       " Row(State='RSP', count=28),\n",
       " Row(State='FSRPA_FSA', count=28),\n",
       " Row(State='S_SPA', count=29),\n",
       " Row(State='S_FRA', count=29),\n",
       " Row(State='SPA_SA', count=29),\n",
       " Row(State='FPA_RPA', count=30),\n",
       " Row(State='S_RPA', count=31),\n",
       " Row(State='SPAC_SPA', count=32),\n",
       " Row(State='FPA_PA', count=37),\n",
       " Row(State='A_A', count=39),\n",
       " Row(State='SRPA_SRPA', count=41),\n",
       " Row(State='FSRA_SA', count=43),\n",
       " Row(State='FSPA_SA', count=45),\n",
       " Row(State='SA_SA', count=56),\n",
       " Row(State='FSR_SA', count=58),\n",
       " Row(State='FSRA_SPA', count=60),\n",
       " Row(State='A_PA', count=60),\n",
       " Row(State='FPA_FA', count=65),\n",
       " Row(State='SA_RPA', count=68),\n",
       " Row(State='PA_R', count=72),\n",
       " Row(State='FSPA_SPA', count=76),\n",
       " Row(State='PA_FPA', count=76),\n",
       " Row(State='FS_', count=78),\n",
       " Row(State='SRPA_FSA', count=81),\n",
       " Row(State='SRA_', count=82),\n",
       " Row(State='FPA_FRPA', count=83),\n",
       " Row(State='S_SRA', count=85),\n",
       " Row(State='PA_', count=89),\n",
       " Row(State='FS_SA', count=91),\n",
       " Row(State='FPA_R', count=96),\n",
       " Row(State='FSRA_FSPA', count=96),\n",
       " Row(State='PA_A', count=97),\n",
       " Row(State='FSPAC_FSPA', count=98),\n",
       " Row(State='FA_', count=100),\n",
       " Row(State='PA_RPA', count=108),\n",
       " Row(State='SPA_FSRA', count=110),\n",
       " Row(State='FPA_', count=112),\n",
       " Row(State='FRPA_FPA', count=116),\n",
       " Row(State='FSA_FSRA', count=119),\n",
       " Row(State='SRA_FSPA', count=119),\n",
       " Row(State='FSRA_FSA', count=142),\n",
       " Row(State='FA_R', count=146),\n",
       " Row(State='FRA_', count=154),\n",
       " Row(State='A_R', count=177),\n",
       " Row(State='FSRPA_FSRPA', count=179),\n",
       " Row(State='FSRPAC_FSPA', count=190),\n",
       " Row(State='FSRPA_SRPA', count=198),\n",
       " Row(State='RPA_PA', count=199),\n",
       " Row(State='SA_SRA', count=204),\n",
       " Row(State='SRA_SPA', count=207),\n",
       " Row(State='FA_FA', count=216),\n",
       " Row(State='FSPA_SRA', count=258),\n",
       " Row(State='URN', count=272),\n",
       " Row(State='FSRPA_SA', count=274),\n",
       " Row(State='TXD', count=278),\n",
       " Row(State='FSPA_SRPA', count=283),\n",
       " Row(State='SPA_SRA', count=286),\n",
       " Row(State='FSPA_FSRA', count=298),\n",
       " Row(State='SRA_FSA', count=329),\n",
       " Row(State='SA_RA', count=368),\n",
       " Row(State='SRPA_SA', count=427),\n",
       " Row(State='FSA_SRA', count=471),\n",
       " Row(State='SRPA_FSRPA', count=475),\n",
       " Row(State='SPA_FSRPA', count=518),\n",
       " Row(State='SR_', count=529),\n",
       " Row(State='R_', count=686),\n",
       " Row(State='SA_FSA', count=711),\n",
       " Row(State='FPA_FPA', count=744),\n",
       " Row(State='A_', count=797),\n",
       " Row(State='RA_', count=906),\n",
       " Row(State='REQ', count=1016),\n",
       " Row(State='FSPA_FSA', count=1076),\n",
       " Row(State='SPA_SRPA', count=1123),\n",
       " Row(State='FSRPA_SPA', count=1515),\n",
       " Row(State='SRA_SA', count=1557),\n",
       " Row(State='RED', count=1559),\n",
       " Row(State='FSA_FSPA', count=1666),\n",
       " Row(State='SPA_FSPA', count=2020),\n",
       " Row(State='URH', count=2096),\n",
       " Row(State='SPA_SPA', count=2526),\n",
       " Row(State='SR_SA', count=2815),\n",
       " Row(State='FSPA_FSRPA', count=3432),\n",
       " Row(State='ECO', count=4134),\n",
       " Row(State='SA_R', count=4352),\n",
       " Row(State='PA_PA', count=4551),\n",
       " Row(State='URP', count=5767),\n",
       " Row(State='S_SA', count=7407),\n",
       " Row(State='SRPA_SPA', count=7572),\n",
       " Row(State='FSRPA_FSPA', count=12645),\n",
       " Row(State='FSA_FSA', count=14457),\n",
       " Row(State='SA_', count=16004),\n",
       " Row(State='SRPA_FSPA', count=26015),\n",
       " Row(State='S_RA', count=32262),\n",
       " Row(State='S_', count=35908),\n",
       " Row(State='INT', count=43297),\n",
       " Row(State='FSPA_FSPA', count=167135),\n",
       " Row(State='CON', count=1470840)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check different types of State\n",
    "df.groupBy('State').count().orderBy('count').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.withColumn(\"State\", when(df4[\"State\"] !=  'CON' , \"Others\").otherwise(df4['State']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(State='Others', count=418301), Row(State='CON', count=1470840)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.groupBy('State').count().orderBy('count').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Dur: double (nullable = true)\n",
      " |-- Proto: string (nullable = true)\n",
      " |-- SrcAddr: string (nullable = true)\n",
      " |-- Sport: string (nullable = true)\n",
      " |-- Dir: string (nullable = true)\n",
      " |-- DstAddr: string (nullable = true)\n",
      " |-- Dport: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- sTos: double (nullable = true)\n",
      " |-- TotPkts: integer (nullable = true)\n",
      " |-- TotBytes: integer (nullable = true)\n",
      " |-- SrcBytes: integer (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      " |-- Attacked: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Dur: double (nullable = true)\n",
      " |-- Proto: string (nullable = true)\n",
      " |-- SrcAddr: string (nullable = true)\n",
      " |-- Sport: string (nullable = true)\n",
      " |-- Dir: string (nullable = true)\n",
      " |-- DstAddr: string (nullable = true)\n",
      " |-- Dport: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- sTos: double (nullable = true)\n",
      " |-- TotPkts: integer (nullable = true)\n",
      " |-- TotBytes: integer (nullable = true)\n",
      " |-- SrcBytes: integer (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      " |-- Attacked: integer (nullable = true)\n",
      " |-- StartTimeIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "#Convert Starttime to Double\n",
    "indexer = StringIndexer(inputCol = 'StartTime', outputCol = 'StartTimeIndex')\n",
    "outputFixed1 = indexer.fit(df5).transform(df5)\n",
    "outputFixed1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Dur: double (nullable = true)\n",
      " |-- Proto: string (nullable = true)\n",
      " |-- SrcAddr: string (nullable = true)\n",
      " |-- Sport: string (nullable = true)\n",
      " |-- Dir: string (nullable = true)\n",
      " |-- DstAddr: string (nullable = true)\n",
      " |-- Dport: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- sTos: double (nullable = true)\n",
      " |-- TotPkts: integer (nullable = true)\n",
      " |-- TotBytes: integer (nullable = true)\n",
      " |-- SrcBytes: integer (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      " |-- Attacked: integer (nullable = true)\n",
      " |-- StartTimeIndex: double (nullable = false)\n",
      " |-- ProtoIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert Proto to Double\n",
    "indexer = StringIndexer(inputCol = 'Proto', outputCol = 'ProtoIndex')\n",
    "outputFixed2 = indexer.fit(outputFixed1).transform(outputFixed1)\n",
    "outputFixed2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Dur: double (nullable = true)\n",
      " |-- Proto: string (nullable = true)\n",
      " |-- SrcAddr: string (nullable = true)\n",
      " |-- Sport: string (nullable = true)\n",
      " |-- Dir: string (nullable = true)\n",
      " |-- DstAddr: string (nullable = true)\n",
      " |-- Dport: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- sTos: double (nullable = true)\n",
      " |-- TotPkts: integer (nullable = true)\n",
      " |-- TotBytes: integer (nullable = true)\n",
      " |-- SrcBytes: integer (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      " |-- Attacked: integer (nullable = true)\n",
      " |-- StartTimeIndex: double (nullable = false)\n",
      " |-- ProtoIndex: double (nullable = false)\n",
      " |-- DirIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert feature Dir to Double\n",
    "indexer = StringIndexer(inputCol = 'Dir', outputCol = 'DirIndex')\n",
    "outputFixed3 = indexer.fit(outputFixed2).transform(outputFixed2)\n",
    "outputFixed3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Dur: double (nullable = true)\n",
      " |-- Proto: string (nullable = true)\n",
      " |-- SrcAddr: string (nullable = true)\n",
      " |-- Sport: string (nullable = true)\n",
      " |-- Dir: string (nullable = true)\n",
      " |-- DstAddr: string (nullable = true)\n",
      " |-- Dport: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- sTos: double (nullable = true)\n",
      " |-- TotPkts: integer (nullable = true)\n",
      " |-- TotBytes: integer (nullable = true)\n",
      " |-- SrcBytes: integer (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      " |-- Attacked: integer (nullable = true)\n",
      " |-- StartTimeIndex: double (nullable = false)\n",
      " |-- ProtoIndex: double (nullable = false)\n",
      " |-- DirIndex: double (nullable = false)\n",
      " |-- StateIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert State into Double\n",
    "indexer = StringIndexer(inputCol = 'State', outputCol = 'StateIndex')\n",
    "outputFixed4 = indexer.fit(outputFixed3).transform(outputFixed3)\n",
    "outputFixed4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#Let us filter and take only the required fields\n",
    "#assembler = VectorAssembler(inputCols = ['StartTime','Proto','Dir','State','sTos','TotPkts','TotBytes','SrcBytes'], outputCol = 'features')\n",
    "assembler = VectorAssembler(inputCols = ['StartTimeIndex','ProtoIndex','DirIndex','StateIndex','sTos','TotPkts','TotBytes','SrcBytes'], outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Dur: double (nullable = true)\n",
      " |-- Proto: string (nullable = true)\n",
      " |-- SrcAddr: string (nullable = true)\n",
      " |-- Sport: string (nullable = true)\n",
      " |-- Dir: string (nullable = true)\n",
      " |-- DstAddr: string (nullable = true)\n",
      " |-- Dport: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- sTos: double (nullable = true)\n",
      " |-- TotPkts: integer (nullable = true)\n",
      " |-- TotBytes: integer (nullable = true)\n",
      " |-- SrcBytes: integer (nullable = true)\n",
      " |-- Label: string (nullable = true)\n",
      " |-- Attacked: integer (nullable = true)\n",
      " |-- StartTimeIndex: double (nullable = false)\n",
      " |-- ProtoIndex: double (nullable = false)\n",
      " |-- DirIndex: double (nullable = false)\n",
      " |-- StateIndex: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = assembler.transform(outputFixed4)\n",
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selct the final columns for model training and building\n",
    "final_df = output.select('features','Attacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Attacked|\n",
      "+--------------------+--------+\n",
      "|[1.0,1.0,1.0,1.0,...|       0|\n",
      "|[1.0,1.0,1.0,1.0,...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train/test dataset\n",
    "train, test = final_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply multiple classification algorithm on the training set and compare the result in the test dataset\n",
    "\n",
    "from pyspark.ml.classification import (DecisionTreeClassifier, RandomForestClassifier,GBTClassifier)\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol = 'Attacked', featuresCol = 'features')\n",
    "rf = RandomForestClassifier(labelCol = 'Attacked', featuresCol = 'features')\n",
    "gb = GBTClassifier(labelCol = 'Attacked', featuresCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = dt.fit(train)\n",
    "rf_model = rf.fit(train)\n",
    "gb_model = gb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions = dt_model.transform(test)\n",
    "rf_predictions = rf_model.transform(test)\n",
    "gb_predictions = gb_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.8208530437840211\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "binary_evaluator = BinaryClassificationEvaluator(labelCol = 'Attacked')\n",
    "print('Decision Tree:', binary_evaluator.evaluate(dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.9309475425857097\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest:' , binary_evaluator.evaluate(rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting: 0.9833524246668374\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting:' , binary_evaluator.evaluate(gb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Attacked: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+\n",
      "|            features|Attacked|      scaledFeatures|\n",
      "+--------------------+--------+--------------------+\n",
      "|[1.0,1.0,1.0,1.0,...|       0|[0.20634591038758...|\n",
      "|[1.0,1.0,1.0,1.0,...|       0|[0.20634591038758...|\n",
      "|[1.0,1.0,1.0,1.0,...|       0|[0.20634591038758...|\n",
      "+--------------------+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol = 'features', outputCol = 'scaledFeatures')\n",
    "scaler_model = scaler.fit(final_df)\n",
    "final_df_cluster = scaler_model.transform(final_df)\n",
    "final_df_cluster.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(featuresCol = 'scaledFeatures', k=8)\n",
    "model = kmeans.fit(final_df_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSSSE: 2717955.0321508106\n"
     ]
    }
   ],
   "source": [
    "print('WSSSE:', model.computeCost(final_df_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.3782426 , 2.15872981, 2.32598973, 2.39111859, 0.00327757,\n",
      "       0.03472349, 0.02610409, 0.01147578]), array([5.00240343e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.98554605e-03, 2.02094908e-03, 3.51419535e-04, 4.10647677e-04]), array([  1.23807546,   2.28878517,   3.11372052,   2.40844699,\n",
      "         0.        , 141.97806282, 105.94839732, 293.76194535]), array([1.65076728e+00, 0.00000000e+00, 2.29432038e+00, 2.40844699e+00,\n",
      "       3.30555122e+02, 6.03979894e-02, 1.57614170e-02, 4.52862470e-02]), array([  2.0634591 ,   2.28878517,   2.29432038,   2.40844699,\n",
      "         0.        , 573.54567957, 719.81145651,  24.29826636]), array([1.71834129e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       4.38010884e-03, 1.71797450e-03, 3.09505716e-04, 3.25878820e-04]), array([2.88344872e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       2.95316043e-03, 1.67392841e-03, 3.05569236e-04, 3.15884812e-04]), array([  1.23807546,   2.28878517,   2.38256347,   2.40844699,\n",
      "         0.        , 174.19250092, 172.44539058,   9.9232795 ])]\n"
     ]
    }
   ],
   "source": [
    "centers = model.clusterCenters()\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|      scaledFeatures|prediction|\n",
      "+--------------------+----------+\n",
      "|[0.20634591038758...|         0|\n",
      "|[0.20634591038758...|         0|\n",
      "|[0.20634591038758...|         0|\n",
      "|[0.20634591038758...|         0|\n",
      "|[0.20634591038758...|         0|\n",
      "|[0.20634591038758...|         0|\n",
      "|[0.20634591038758...|         0|\n",
      "|[0.20634591038758...|         0|\n",
      "|[0.20634591038758...|         0|\n",
      "|[0.20634591038758...|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(final_df_cluster).select('scaledFeatures', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+----------+\n",
      "|            features|Attacked|      scaledFeatures|prediction|\n",
      "+--------------------+--------+--------------------+----------+\n",
      "|[1.0,1.0,1.0,1.0,...|       0|[0.20634591038758...|         0|\n",
      "|[1.0,1.0,1.0,1.0,...|       0|[0.20634591038758...|         0|\n",
      "+--------------------+--------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(final_df_cluster).show(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
